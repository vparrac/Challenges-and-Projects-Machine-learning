{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1\n",
    "## Data cleansing\n",
    "Before to load the data to python, it was necessary clean data set. For this purpose the set of songs that belong to music genders different to _Jazz & Blues_ or _Soul and Reaggae_ were deleted. The string attributes also were deleted. After, the representation of classes was changed, it was selected \"0\" to representate the class _Jazz & Blues_ and \"1\" to representate the class Soul and Reagge.\n",
    "\n",
    "The cleaned data was load to python with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import nunpy to read data\n",
    "import numpy as np\n",
    "# SKLearn is used to make the logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# In order to split randomply train_test_split method (of SKLearn) will be user\n",
    "from sklearn.model_selection import train_test_split\n",
    "# To evalue the results a confusi√≥n matrix and ACA were used\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "#Import data\n",
    "data = np.genfromtxt('clean_data.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary separate the class of the features on the clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels= data[:,0]\n",
    "features = data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part one: Train the algorithm using all data\n",
    "This challenge is divided in four parts. In the first part all the data will be used. To separte the training data of test data the train_test_split was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training set, we can create the logistic regression. The solver parameter was fixed in newton-cg in order to facilitate the convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver = \"sag\", max_iter=100000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model created we can predict the new classes with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results we will use the confusion matrix (CM) and the accuracy score (ACA). In the columns of CM representate the actual class 0 and the predicted class 1, the rows representate the predicted data class\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">Actual class<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\"><br>Predicted</td>\n",
    "    <td>0<br></td>\n",
    "    <td><span style=\"color:rgb(51, 51, 51)\">TP</span></td>\n",
    "    <td>FP<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>FN</td>\n",
    "    <td>TN</td>\n",
    "  </tr>\n",
    "</table>\n",
    "The ACA number is defined as\n",
    "$ACA= \\frac{TP}{TP+FP}+\\frac{TN}{FN+TN}=0.83$\n",
    "\n",
    "This means that our model have 83% pf hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[716 164]\n",
      " [125 665]]\n",
      "0.8269461077844311\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, predictions) \n",
    "ACA = accuracy_score(y_test, predictions) \n",
    "print(matrix)\n",
    "print(ACA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part two: Train the algorithm using 50% of data\n",
    "In this part we will use only de half of data to training and test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the half-data we separate the set again into training and test sets.\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_train, y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(solver = \"sag\", max_iter=100000).fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[704 176]\n",
      " [120 670]]\n",
      "0.822754491017964\n"
     ]
    }
   ],
   "source": [
    "matrix2 = confusion_matrix(y_test, predictions2) \n",
    "ACA2 = accuracy_score(y_test, predictions2) \n",
    "print(matrix2)\n",
    "print(ACA2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part three: Train the algorithm using 20% of data\n",
    "In this part we will use only the 20% of data to training and test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the half-data we separate the set again into training and test sets.\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_train, y_train, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = LogisticRegression(solver = \"sag\", max_iter=100000).fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[704 176]\n",
      " [139 651]]\n",
      "0.811377245508982\n"
     ]
    }
   ],
   "source": [
    "matrix3 = confusion_matrix(y_test, predictions3) \n",
    "ACA3 = accuracy_score(y_test, predictions3) \n",
    "print(matrix3)\n",
    "print(ACA3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part four: Train the algorithm using 10% of data\n",
    "In this part we will use only the 10% of data to training and test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the half-data we separate the set again into training and test sets.\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X_train, y_train, test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = LogisticRegression(solver = \"sag\", max_iter=100000).fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = clf4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[719 161]\n",
      " [157 633]]\n",
      "0.8095808383233533\n"
     ]
    }
   ],
   "source": [
    "matrix4 = confusion_matrix(y_test, predictions4) \n",
    "ACA4 = accuracy_score(y_test, predictions4) \n",
    "print(matrix4)\n",
    "print(ACA4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8269461077844311 0.822754491017964 0.811377245508982 0.8095808383233533\n"
     ]
    }
   ],
   "source": [
    "print(ACA,ACA2,ACA3,ACA4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACA number almost no has variation between models. This facts sugest that or our data is very linear or every class is very grouped, for this reason the accuracy of model is not improved significaly with the among of data, a small set is significant enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
