{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2\n",
    "## Dependencies\n",
    "To run this code is necessary numpy and sklearn libraries.\n",
    "## Description\n",
    "The objective of this challenge is classify data in two classes: _Jazz & Blues_ and _Soul and Reaggae_ using a logistic regresión.\n",
    "## Data cleansing\n",
    "Before to load the data to python, it was necessary clean data set. For this purpose the set of songs that belong to music genders different to _Jazz & Blues_ or _Soul and Reaggae_ were deleted. The string attributes also were deleted. After, the representation of classes was changed, it was selected \"0\" to representate the class _Jazz & Blues_ and \"1\" to representate the class Soul and Reagge.\n",
    "\n",
    "The cleaned data was load to python with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#numpy to read data\n",
    "import numpy as np\n",
    "# We use sklearn to split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# We use the confusion matrix to evaluate the model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# We use aca nmber to evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Random for LMS method\n",
    "import random\n",
    "# Got mathematics operations\n",
    "import math\n",
    "\n",
    "#importar los datos\n",
    "data = np.genfromtxt('clean_data.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, it is separate the class of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels= data[:,0]\n",
    "features = data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part one: Train the algorithm using all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use SGD algorithm to find the parameters of logistical regresión, the definition of the method is the following. To select the learning rate I variate manually this parameter, I noticed that in a big values of this parameter the method began to diverge, so I iterate and at the end i noticed that the bigger number that the algortithm toletare was 1e-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(features, labels):\n",
    "    size = len(features[0])\n",
    "    w0 = np.array([1e-2]*size)\n",
    "    num = 1e-6\n",
    "    for i in range(1000000):\n",
    "        rand_index = random.randint(0,len(labels)-1)\n",
    "        xi, yi = (features[rand_index],labels[rand_index])\n",
    "        g = 1 / (1 + math.exp(-np.dot(w0,xi)))\n",
    "        e = yi - g\n",
    "        w1 = w0 + num*e*xi\n",
    "        #err = np.linalg.norm(w1-w0)\n",
    "        w0 = np.copy(w1)\n",
    "    #print(w0)\n",
    "    return w0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the algorithm with the correct parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = SGD(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the algorithm, I did predictios with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in X_test:\n",
    "    y = 1 / (1 + math.exp(-np.dot(w0,x)))\n",
    "    y = 1 if y>=0.5 else 0\n",
    "    predictions.append(y)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results we will use the confusion matrix (CM) and the accuracy score (ACA). In the columns of CM representate the actual class 0 and the predicted class 1, the rows representate the predicted data class\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">Actual class<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\"><br>Predicted</td>\n",
    "    <td>0<br></td>\n",
    "    <td><span style=\"color:rgb(51, 51, 51)\">TP</span></td>\n",
    "    <td>FP<br></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>FN</td>\n",
    "    <td>TN</td>\n",
    "  </tr>\n",
    "</table>\n",
    "The ACA number is defined as following equation and its representate the average of data that was predicted in the correct class divided the number of records predicted for this class for each class.\n",
    "$ACA= \\frac{1}{2}\\frac{TP}{TP+FP}+\\frac{1}{2}\\frac{TN}{FN+TN}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matriz\n",
      "[[828  24]\n",
      " [449 369]]\n",
      "Accuracy number\n",
      "0.7167664670658682\n"
     ]
    }
   ],
   "source": [
    "matrix1 = confusion_matrix(y_test, predictions) \n",
    "ACA1 = accuracy_score(y_test, predictions) \n",
    "print('Confusion matriz')\n",
    "print(matrix1)\n",
    "print('Accuracy number')\n",
    "print(ACA1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part two: Train the algorithm using 50% of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.5)\n",
    "w0 = SGD(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in X_test:\n",
    "    y = 1 / (1 + math.exp(-np.dot(w0,x)))\n",
    "    y = 1 if y>=0.5 else 0\n",
    "    predictions.append(y)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[552 300]\n",
      " [ 43 775]]\n",
      "Accuracy number\n",
      "0.7946107784431138\n"
     ]
    }
   ],
   "source": [
    "matrix2 = confusion_matrix(y_test, predictions) \n",
    "ACA2 = accuracy_score(y_test, predictions)\n",
    "print('Confusion matrix')\n",
    "print(matrix2)\n",
    "print('Accuracy number')\n",
    "print(ACA2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part three: Train the algorithm using 20% of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_train, y_train, test_size=0.8)\n",
    "w0 = SGD(X_train3,y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in X_test:\n",
    "    y = 1 / (1 + math.exp(-np.dot(w0,x)))\n",
    "    y = 1 if y>=0.5 else 0\n",
    "    predictions.append(y)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[453 399]\n",
      " [ 23 795]]\n",
      "Accuracy number\n",
      "0.7473053892215569\n"
     ]
    }
   ],
   "source": [
    "matrix3 = confusion_matrix(y_test, predictions) \n",
    "ACA3 = accuracy_score(y_test, predictions)\n",
    "print('Confusion matrix')\n",
    "print(matrix3)\n",
    "print('Accuracy number')\n",
    "print(ACA3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part four: Train the algorithm using 10% of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X_train, y_train, test_size=0.9)\n",
    "w0 = SGD(X_train4,y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in X_test:\n",
    "    y = 1 / (1 + math.exp(-np.dot(w0,x)))\n",
    "    y = 1 if y>=0.5 else 0\n",
    "    predictions.append(y)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[619 233]\n",
      " [ 82 736]]\n",
      "Accuracy number\n",
      "0.811377245508982\n"
     ]
    }
   ],
   "source": [
    "matrix4 = confusion_matrix(y_test, predictions) \n",
    "ACA4 = accuracy_score(y_test, predictions)\n",
    "print('Confusion matrix')\n",
    "print(matrix4)\n",
    "print('Accuracy number')\n",
    "print(ACA4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7167664670658682 0.7946107784431138 0.7473053892215569 0.811377245508982\n"
     ]
    }
   ],
   "source": [
    "print(ACA1,ACA2,ACA3,ACA4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the accuracy of the models is significally diferent. In this challenge, we can note a big differences when the training set is reduced, this implies that SKLearn library has a more complex model with a better accuracy. Nevertheless, even SDG is not a fine model, with the enough among of data we can obtain a close accuracy to SKLearn model. In terms cost and benefits SDG algorithm give as a good model in a reasonable time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valerie Parra Cortés\n",
    "201619703"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
